\begin{frame}[fragile,label=covMinEx]{simplifying testing cases}
\begin{lstlisting}[style=script]
int array[10];
void vulnerable(char *input) {
    char *p;
    int count = 0;
    p = input;
    if (*p == 'A') { 
        p += 1;
        while (*p == '0') {p += 1; count -= 1;}
        while (*p >= 'A' && *p < 'E') p += 1;
        while (*p == '0') {p += 1; count += 1;}
    }
    if (*p == 'B')
        array[count] += 1;
}
\end{lstlisting}
\begin{itemize}
\item example crash: {\small\texttt{A00ABDBBBDEEDDDCCCBBBDDDAAAA00000000000000000000000B}}
    \begin{itemize}
    \item might be what coverage-guided fuzzing finds
    \end{itemize}
\item would really prefer minimal example: \texttt{A00000000000B}
\end{itemize}
\end{frame}


\begin{frame}[fragile,label=covMin]{automatically simplifying test cases}
    \begin{itemize}
        \item but look for \myemph{same result and/or coverage}
        \item systematic simplifications:
            \begin{itemize}
                \item try removing every character (one-by-one)
                \item try decrementing every byte
                \item \ldots
            \end{itemize}
        \item keep simplifications that don't change result
        \item AFL uses some of this strategy to help get better `base' tests
            \begin{itemize}
            \item also has tool to do this on a found test
            \item prefers simpler `base' tests
            \end{itemize}
    \end{itemize}
\end{frame}
